<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Hadoop HDFS Operation - BF Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="BF Blog"><meta name="msapplication-TileImage" content="/img/favicon.ico"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="BF Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="背景之前搭好了 Hadoop 环境，但是在使用的过程中还是有一些问题，现在终于解决了，至少最基础的环境没有问题了。 基本环境Hadoop-2.7.3 &amp;#x2F; Java7 四台机子如下，hadoop00 为mater, 其余为 slave 1234192.168.137.100 hadoop00192.168.137.101 hadoop01192.168.137.102 hadoop02192.168"><meta property="og:type" content="blog"><meta property="og:title" content="Hadoop HDFS Operation"><meta property="og:url" content="https://bearfly1990.github.io/2019/02/17/2019/02/2019-02-17-HDFSOperation/"><meta property="og:site_name" content="BF Blog"><meta property="og:description" content="背景之前搭好了 Hadoop 环境，但是在使用的过程中还是有一些问题，现在终于解决了，至少最基础的环境没有问题了。 基本环境Hadoop-2.7.3 &amp;#x2F; Java7 四台机子如下，hadoop00 为mater, 其余为 slave 1234192.168.137.100 hadoop00192.168.137.101 hadoop01192.168.137.102 hadoop02192.168"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://bearfly1990.github.io/img/og_image.png"><meta property="article:published_time" content="2019-02-16T16:00:00.000Z"><meta property="article:modified_time" content="2021-08-30T12:46:11.914Z"><meta property="article:author" content="BF"><meta property="article:tag" content="hadoop"><meta property="article:tag" content="java"><meta property="article:tag" content="big data"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://bearfly1990.github.io/2019/02/17/2019/02/2019-02-17-HDFSOperation/"},"headline":"Hadoop HDFS Operation","image":["https://bearfly1990.github.io/img/og_image.png"],"datePublished":"2019-02-16T16:00:00.000Z","dateModified":"2021-08-30T12:46:11.914Z","author":{"@type":"Person","name":"BF"},"publisher":{"@type":"Organization","name":"BF Blog","logo":{"@type":"ImageObject","url":"https://bearfly1990.github.io/img/favicon.ico"}},"description":"背景之前搭好了 Hadoop 环境，但是在使用的过程中还是有一些问题，现在终于解决了，至少最基础的环境没有问题了。 基本环境Hadoop-2.7.3 &#x2F; Java7 四台机子如下，hadoop00 为mater, 其余为 slave 1234192.168.137.100 hadoop00192.168.137.101 hadoop01192.168.137.102 hadoop02192.168"}</script><link rel="canonical" href="https://bearfly1990.github.io/2019/02/17/2019/02/2019-02-17-HDFSOperation/"><link rel="icon" href="/img/favicon.ico"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/favicon.ico" alt="BF Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/bearfly1990"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-02-16T16:00:00.000Z" title="2019/2/17 上午12:00:00">2019-02-17</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-08-30T12:46:11.914Z" title="2021/8/30 下午8:46:11">2021-08-30</time></span><span class="level-item"> BF </span><span class="level-item">6 minutes read (About 889 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">Hadoop HDFS Operation</h1><div class="content"><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>之前搭好了 Hadoop 环境，但是在使用的过程中还是有一些问题，现在终于解决了，至少最基础的环境没有问题了。</p>
<h1 id="基本环境"><a href="#基本环境" class="headerlink" title="基本环境"></a>基本环境</h1><p>Hadoop-2.7.3 / Java7</p>
<p>四台机子如下，<strong>hadoop00</strong> 为<strong>mater</strong>, 其余为 slave</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">192.168.137.100 hadoop00</span><br><span class="line">192.168.137.101 hadoop01</span><br><span class="line">192.168.137.102 hadoop02</span><br><span class="line">192.168.137.103 hadoop03</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h1 id="HDFS-的相关命令"><a href="#HDFS-的相关命令" class="headerlink" title="HDFS 的相关命令"></a>HDFS 的相关命令</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">-mkdir            在HDFS创建目录    hdfs dfs -mkdir &#x2F;data</span><br><span class="line">-ls               查看当前目录      hdfs dfs -ls &#x2F;</span><br><span class="line">-ls -R            查看目录与子目录</span><br><span class="line">-put              上传一个文件      hdfs dfs -put data.txt &#x2F;data&#x2F;input</span><br><span class="line">-moveFromLocal    上传一个文件，会删除本地文件：ctrl + X</span><br><span class="line">-copyFromLocal    上传一个文件，与put一样</span><br><span class="line">-copyToLocal      下载文件  hdfs dfs -copyToLocal &#x2F;data&#x2F;input&#x2F;data.txt</span><br><span class="line">-get              下载文件  hdfs dfs -get &#x2F;data&#x2F;input&#x2F;data.txt</span><br><span class="line">-rm               删除文件  hdfs dfs -rm &#x2F;data&#x2F;input&#x2F;data.txt</span><br><span class="line">-getmerge         将目录所有的文件先合并，再下载</span><br><span class="line">-cp               拷贝： hdfs dfs -cp &#x2F;data&#x2F;input&#x2F;data.txt  &#x2F;data&#x2F;input&#x2F;data01.txt</span><br><span class="line">-mv               移动： hdfs dfs -mv &#x2F;data&#x2F;input&#x2F;data.txt  &#x2F;data&#x2F;input&#x2F;data02.txt</span><br><span class="line">-count            统计目录下的文件个数</span><br><span class="line">-text、-cat       查看文件的内容  hdfs dfs -cat &#x2F;data&#x2F;input&#x2F;data.txt</span><br><span class="line">-balancer         平衡操作</span><br></pre></td></tr></table></figure>

<h1 id="使用-Java-进行-HDFS-基本操作"><a href="#使用-Java-进行-HDFS-基本操作" class="headerlink" title="使用 Java 进行 HDFS 基本操作"></a>使用 Java 进行 HDFS 基本操作</h1><p>下面是一个非常简单的例子，需要说明的是，”root”是那台 Linux 上有权限的用户名，不然会报权限错误，有多种解决方案，可以参考：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/bkylry/p/8072132.html">HDFS JAVA 客户端的权限错误：Permission denied</a></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.bearfly.fun.hadooplearn;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"><span class="keyword">import</span> java.net.URISyntaxException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* <span class="doctag">@Description</span>: App</span></span><br><span class="line"><span class="comment">* <span class="doctag">@author</span> bearfly1990</span></span><br><span class="line"><span class="comment">* <span class="doctag">@date</span> Feb 17, 2019 10:18:42 PM</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">App</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException </span>&#123;</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        FileSystem fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">&quot;hdfs://hadoop00:9000&quot;</span>), conf, <span class="string">&quot;root&quot;</span>);</span><br><span class="line">        fs.mkdirs(<span class="keyword">new</span> Path(<span class="string">&quot;/folder1&quot;</span>));</span><br><span class="line"></span><br><span class="line">        Path src = <span class="keyword">new</span> Path(<span class="string">&quot;d:/test.txt&quot;</span>);</span><br><span class="line">        Path dst = <span class="keyword">new</span> Path(<span class="string">&quot;/folder1&quot;</span>);</span><br><span class="line">        fs.copyFromLocalFile(src, dst);</span><br><span class="line">        fs.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>网上有更多详细的例子。</p>
<p>最后的运行结果如下（加上上面创建的文件）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop00 ~]<span class="comment"># hdfs dfs -ls -R /</span></span><br><span class="line">drwxr-xr-x   - root supergroup          0 2019-02-17 21:23 /data</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2019-02-17 21:25 /data/input</span><br><span class="line">-rw-r--r--   3 root supergroup         68 2019-02-17 21:25 /data/input/word-count-data.txt</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2019-02-17 21:23 /data/output</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2019-02-17 22:10 /folder1</span><br><span class="line">-rw-r--r--   3 root supergroup         20 2019-02-17 22:10 /folder1/test.txt</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="WARN-util-NativeCodeLoader-Unable-to-load-native-hadoop-library-for-your-platform…-using-builtin-java-classes-where-applicable"><a href="#WARN-util-NativeCodeLoader-Unable-to-load-native-hadoop-library-for-your-platform…-using-builtin-java-classes-where-applicable" class="headerlink" title="WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable"></a>WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable</h1><p>在使用的过程中一直有报这样的 Warning,虽然可以正常运行，但是看着很烦。</p>
<p>网上有许多的问题和对应解决方案，而我这个编译的版本什么都是一样的，只要在环境变量中添加 HADOOP_OPTS 即可。</p>
<p>具体分析的时候可以把 Hadoop 的 debug log 打开<code>$ export HADOOP_ROOT_LOGGER=DEBUG,console</code>，找到对应的信息。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># /etc/profile</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_OPTS=<span class="string">&quot;-Djava.library.path=<span class="variable">$&#123;HADOOP_HOME&#125;</span>/lib/native&quot;</span></span><br></pre></td></tr></table></figure>

<h1 id="DataNode-Crashed"><a href="#DataNode-Crashed" class="headerlink" title="DataNode Crashed"></a>DataNode Crashed</h1><p>在使用的过程中，我还遇到了DataNode失效了。我找不到原因，所以stop hdfs 和 yarn 之后重新format了一下就好了。</p>
<p>注：在这过程中我关闭了防火墙，删除原始的目录，排除了可能的影响。</p>
<p>更多信息可以参考最后的链接。</p>
<hr>
<p>参考：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/bkylry/p/8072132.html">HDFS JAVA 客户端的权限错误：Permission denied</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/likui360/p/6558749.html">Hadoop 出现错误：WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable，解决方案</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/l1028386804/article/details/51538611">Hadoop之—— WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform…</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/l1028386804/article/details/72857449">Hadoop之——重新格式化HDFS的方案</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/lizhonghua34/p/6437878.html">java使用FileSystem上传文件到hadoop文件系统</a></li>
</ul>
</div><div class="article-licensing box"><div class="licensing-title"><p>Hadoop HDFS Operation</p><p><a href="https://bearfly1990.github.io/2019/02/17/2019/02/2019-02-17-HDFSOperation/">https://bearfly1990.github.io/2019/02/17/2019/02/2019-02-17-HDFSOperation/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>BF</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2019-02-17</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2021-08-30</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/hadoop/">hadoop</a><a class="link-muted mr-2" rel="tag" href="/tags/java/">java</a><a class="link-muted mr-2" rel="tag" href="/tags/big-data/">big data</a></div><div class="sharethis-inline-share-buttons"></div><script src="http://localhost:4000" defer></script></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2019/02/19/2019/02/2019-02-19-Py2DifferPy3/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Difference between Python2 and Python3</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2019/01/20/2019/01/2019-01-20-CompareExcel/"><span class="level-item">Compare Excel</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/mybear.jpg" alt="bearfly1990"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">bearfly1990</p><p class="is-size-6 is-block">有熊在飞</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>HZ, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">94</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">5</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">116</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/bearfly1990" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/bearfly1990"><i class="fab fa-github"></i></a></div></div></div><!--!--></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/favicon.ico" alt="BF Blog" height="28"></a><p class="is-size-7"><span>&copy; 2022 BF</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>